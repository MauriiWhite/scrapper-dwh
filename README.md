# Scrapper Data Warehouse Project

## ğŸ“œ DescripciÃ³n

**Scrapper** es un **Data Warehouse** diseÃ±ado para gestionar datos de productos de computaciÃ³n extraÃ­dos de una URL especÃ­fica. Este proyecto utiliza un modelo dimensional con un esquema en estrella y ha sido implementado mediante ingenierÃ­a inversa para realizar web scraping de los datos de productos.

El proyecto incluye las siguientes tablas predeterminadas:

- **Product**: InformaciÃ³n detallada sobre los productos.
- **Customer**: Datos de los clientes.
- **Branch**: InformaciÃ³n sobre las sucursales.
- **Sales**: Tabla principal para el anÃ¡lisis de datos.

> [!NOTE]
> La extracciÃ³n de datos de productos se ha realizado mediante tÃ©cnicas de web scraping y un proceso de ingenierÃ­a inversa para adaptar la estructura de los datos a las necesidades del Data Warehouse.

## ğŸ“ Estructura del Proyecto

El proyecto estÃ¡ organizado en las siguientes carpetas y archivos:

- **`data/`**: Carpeta que contiene varios archivos en diferentes formatos para fines demostrativos.
- **`requirements.txt`**: Archivo que lista las dependencias necesarias para el proyecto. AsegÃºrate de instalar estas dependencias antes de ejecutar el proyecto.
- **`scrapper/`**: Contiene el cÃ³digo principal para realizar el scraping de datos a partir de la URL especificada.

> [!WARNING]
> Debido a restricciones de propiedad intelectual, la URL para el scrapper no estÃ¡ disponible pÃºblicamente. Como resultado, el scrapper no puede ser ejecutado sin la URL vÃ¡lida.

- **`src/`**: Carpeta con los archivos de ejecuciÃ³n principal del proyecto. Incluye los scripts y mÃ³dulos esenciales que forman el nÃºcleo del sistema.
- **`test/`**: Carpeta destinada a las pruebas. Contiene scripts para transformar archivos y validar los datos en los formatos adecuados para pruebas.
- **`config.toml`**: Archivo de configuraciÃ³n utilizado para ajustar las peticiones HTTP del scrapper. Permite personalizar la conexiÃ³n y la forma en que se envÃ­an las solicitudes.
- **`packages.ps1`**: Script de PowerShell para actualizar las dependencias del proyecto en sistemas **Windows**.

## ğŸ› ï¸ Requisitos

Antes de comenzar con el proyecto, asegÃºrate de tener instalados los siguientes componentes:

- **Python**: VersiÃ³n 3.10 o superior. Puedes descargarlo desde [python.org](https://www.python.org/downloads/).
- **XAMPP**: Para crear y gestionar la base de datos. DescÃ¡rgalo e instÃ¡lalo desde [apachefriends.org](https://www.apachefriends.org/).

## ğŸš€ Instrucciones de ConfiguraciÃ³n

Sigue estos pasos para configurar el entorno de desarrollo y preparar el proyecto para su uso:

1. **Configura la Base de Datos**:
   - Abre XAMPP y inicia los servicios de **Apache** y **MySQL**.
   - Accede a **phpMyAdmin** desde tu navegador en `http://localhost/phpmyadmin/`.
   - Crea una nueva base de datos llamada **store**.

2. **Configura el Entorno de Python**:
   - **Crear un Entorno Virtual**:
     Se recomienda crear un entorno virtual para gestionar las dependencias del proyecto de manera aislada. Ejecuta el siguiente comando en tu terminal:

     ```bash
     python -m venv venv
     ```

   - **Activar el Entorno Virtual**:
     - En **Windows**:

       ```bash
       venv\Scripts\activate
       ```

     - En **macOS** o **Linux**:

       ```bash
       source venv/bin/activate
       ```

   - **Instalar las Dependencias**:
     Con el entorno virtual activado, instala las dependencias necesarias utilizando el archivo `requirements.txt`:

     ```bash
     pip install -r requirements.txt
     ```

   **Nota**: AsegÃºrate de tener `pip` actualizado para evitar problemas de instalaciÃ³n.

Siguiendo estos pasos, tendrÃ¡s tu entorno de desarrollo configurado y listo para utilizar **Scrapper Data Warehouse**.

## ğŸ“ Uso

Sigue estos pasos para ejecutar el scrapper y verificar que los datos se hayan gestionado correctamente:

1. **Configura la Base de Datos**:
   - AsegÃºrate de que la base de datos **store** estÃ© correctamente configurada y en funcionamiento en XAMPP.

2. **Ejecuta el Scrapper**:
   - **En Windows**:

     Abre la terminal (cmd o PowerShell) y navega al directorio del proyecto. Ejecuta el siguiente comando para iniciar el scrapper:

     ```bash
     python src\main.py
     ```

   - **En macOS o Linux**:

     Abre la terminal y navega al directorio del proyecto. Ejecuta el siguiente comando para iniciar el scrapper:

     ```bash
     python3 src/main.py
     ```

3. **Verifica los Datos**:
   - Revisa los datos extraÃ­dos en la base de datos **store** para asegurarte de que el proceso se completÃ³ correctamente. Puedes usar **phpMyAdmin** para inspeccionar las tablas y validar la informaciÃ³n.

Si encuentras algÃºn problema durante la ejecuciÃ³n o en la verificaciÃ³n de los datos, revisa los mensajes de error en la terminal y asegÃºrate de que todas las configuraciones sean correctas.

## ğŸ˜Š Agradecimientos

Gracias por usar **Scrapper Data Warehouse**. Espero que este proyecto te sea de utilidad.

> Atte. ***Maurii White***
